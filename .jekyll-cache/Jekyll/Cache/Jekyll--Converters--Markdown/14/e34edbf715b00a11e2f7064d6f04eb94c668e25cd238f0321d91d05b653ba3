I"Ñ5<p>Here I skip the definitions and some qualitative concerns for the interpretability
and move on to the interpretable models from Molnar‚Äôs reference<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. The models introduced in this post are
more like statistically founded approaches, which means they might not be able to
applicable to complex tasks such as speech recognition or object detection. 
Nevertheless, first things first. Here I introduce 6+ ‚Äòclassical‚Äô models for 
<em>classification</em> and <em>regression</em>.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>Algorithm</strong></th>
      <th style="text-align: center"><strong>Linear</strong></th>
      <th style="text-align: center"><strong>Monotone</strong></th>
      <th style="text-align: center"><strong>Interaction</strong></th>
      <th style="text-align: center"><strong>Classification</strong></th>
      <th style="text-align: center"><strong>Regression</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="#linear-regression">Linear regression</a></td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#">Logistic regression</a></td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="/2021/06/19/interpretable-ml-02.html">Decision trees</a></td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">?</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#rulefit">RuleFit</a></td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#naive-bayes">Naive Bayes</a></td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="#k-nearest-neighbours">k-NN</a></td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>A table from <em>Interpretable Machine Learning</em>, Molnar(2021)<sup id="fnref:1:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>
</blockquote>

<p>Here, each criterion stands for:</p>
<ul>
  <li>Linear: whether the association between features and target is linear</li>
  <li>Monontone: whether the change in the feature space always monotonically affects the target</li>
  <li>Interaction: whether the model innately consists of interactive features</li>
</ul>

<h2 id="linear-regression">Linear regression</h2>

<p>The structure genrerally follows the <a href="https://christophm.github.io/interpretable-ml-book/limo.html">Molnar‚Äôs page</a>,
but I added some insights from the ETHZ Computational Statistics‚Äô lecture notes.</p>

<h3 id="formalisation">Formalisation</h3>

<p>The classic. Linear regression is the simplest model which predicts the target
as a weighted sum of the feature inputs. Let‚Äôs do a quick recap of the process.
Denote the target values $\mathbf{y} \in \mathbb{R}^n$ and the features 
$\mathbf{X} \in \mathbb{R}^{n \times p}$ including interceptions. With the 
intractable noise $\mathbf{\epsilon}$, we assume the latent relationship:</p>

\[y_i = \beta_1 x_{i,1} + \cdots + \beta_p x_{i,p} + \epsilon_i,\ \forall i \in [n]\]

<p>or</p>

\[\mathbf{y} = \mathbf{X} \mathbf{\beta} + \mathbf{\epsilon}\]

<p>and aproximate the weight vector $\mathbf{\beta}$ with:</p>

\[\hat{\beta} = \arg\min_{\mathbf{b}} \sum_{i=1}^{n} (y_i - \mathbf{x}_i^\intercal \mathbf{b})^2 
= \arg\min_{\mathbf{b}} (\mathbf{Y} - \mathbf{X} \mathbf{b})^\intercal (\mathbf{Y} - \mathbf{X} \mathbf{b}) 
= (\mathbf{X}^\intercal \mathbf{X})^{-1} \mathbf{X}^\intercal \mathbf{Y}\]

<p>Pretty straightforward, isn‚Äôt it? Also, if we assume all the noise are drawn from
the i.i.d. normal distribution, i.e., $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$, then
we also can approximate $\sigma^2$ with</p>

\[\hat{\sigma^2} = \frac{1}{n-p} \sum_{i=1}^n (y_i - \mathbf{x}_i^\intercal \hat{\beta})^2 
\sim \frac{\sigma^2}{n-p} \chi^2_{n-p}\]

<p>and can derive the distribution of $\hat{\beta}$:</p>

\[\hat{\beta} \sim \mathcal{N}_p ( \mathbf{\beta}, \sigma^2 (\mathbf{X}^\intercal \mathbf{X})^{-1})\]

<p>Note that linear regression looks elegant, but it bases heavy assumptions for
the data which are listed below:</p>

<ul>
  <li><em>Linearity</em> between the features and the target.</li>
  <li><em>Normality</em> of the features for the confidence interval of each weight (which will be shown later)</li>
  <li><em>Homoscedasticity (constant variance)</em> of the error terms.</li>
  <li><em>Independence</em> among the data points.</li>
  <li><em>Fixed features</em>, which means the data points are not variables but given constants.</li>
  <li><em>Absence of multicollinearity</em>, which means the independence among the features.</li>
</ul>

<h3 id="model-selections">Model selections</h3>

<p>If there are too many features, we might want to reduce the dimension of the feature
spaces while we don‚Äôt lose the predictive power or any other performance measure. 
There are majorly three ways to do so: subset selection, shrinkage, and
dimension reduction (i.e., principal component analysis). The last one is hard to
interpret, so let‚Äôs concentrate on the rests.</p>

<ul>
  <li><strong>Subset selection</strong></li>
</ul>

<p>When we want select only $q$ features from the data, the best way to do this is 
to consider $\binom{p}{q}$ models and choose the ‚Äúbest‚Äù model among those. However,
this approach is computationally heavy, so we often do the greedy approaches
in either forward or backward direction to choose the models among the limited scopes.
This field is not dead yet - you can see the presentation pdf for the seminar
handled this topic in <a href="/assets/images/07_11_SubmodularMeetsSpectral.pdf">here</a>, if you‚Äôre interested in :)</p>

<p>Here, we often choose the criteria of the ‚Äúbest‚Äù model from <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">Akaike Information Criterion (AIC)</a>,
<a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">Bayesian Information Criterion</a>, or adjusted R-squared, which will be explained later.</p>

<ul>
  <li><strong>Shrinkage</strong></li>
</ul>

<p>Two veins of the shrinkage methods are prevailing: <em>Lasso</em> and <em>Ridge</em>. Those
are often called as <em>regularisation</em> techniques as well, as they regularise the
L1-norm and L2-norm of the weights $\beta$, respectively. With attaching the
regularising term on the objective function with the scale parameter $\lambda$,
Ridge regression on the standardised data can be explicitly written:</p>

\[\hat\beta^{Ridge} = (\mathbf{X}^\intercal \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^\intercal \mathbf{y},\]

<p>but Lasso only have numerical solutions via least angle regression (iterative algorithm) or so.</p>

<p><img src="/assets/images/2021-05-15-lasso.png" alt="lasso" /></p>
<blockquote>
  <p>Lasso regression‚Äôs feature weights vs $\lambda$. Note that the more weights goes zero as $\lambda$ grows.</p>
</blockquote>

<p>The funny thing here is that while Ridge still shows the continuous weights among
all the features, Lasso regression innately ‚Äúselects‚Äù the important features when
the regularisation parameter $\lambda$ is big enough. From this property, we can
shrink the model size based on the importance of each feature.</p>

<h3 id="interpretation">Interpretation</h3>

<ul>
  <li><strong>Weights $\beta$</strong></li>
</ul>

<p>We can interpret the results of the linear regression: for $k$-th feature, $x_{\cdot, k}$, 
$\hat\beta_k$ is the expectation of the result gap of the two inputs share all the
features but differ in $k$-th with 1. You can derive it easily by the linearity.
This interpretation holds for both numerical features and categorical features.</p>

<p>Also, the <em>feature importance</em> of $x_k$ is measured by the absolute value of the
t-statistic:</p>

\[t_{\hat\beta_k} = \frac{\hat\beta_k}{se(\hat\beta_k)},\]

<p>where $se$ is the standard error.</p>

<ul>
  <li><strong>R-squared measurement</strong></li>
</ul>

<p>R-squared or $R^2$ is the measurement represents the portion of variance in $y$
that is explained by the linear regression model. It is defined as:</p>

\[R^2 = 1 - \frac{RSS}{TSS},\]

<p>where</p>

\[RSS = \sum_{i-1}^n (y_i - \hat{y}_i)^2,\ TSS = \sum_{i=1}^n (y_i - \bar{y}_i)^2\]

<p>RSS stands for the <em>residual sum of squares</em> and TSS is for <em>total sum of squares</em>.
Each of term can be interpreted as following: $RSS/(n-1)$ is the sample variance
of the residuals $\epsilon_1, \cdots \epsilon_n$, and $TSS/(n-1)$ is the sample
variance of the data labels $y_1, \cdots y_n$. Hence, $RSS/TSS$ should be low
if the model works well, which directly implies that the higher $R^2$ is, the better
the model is.</p>

<p>Here, we can also consider the <em>adjusted R-squared</em> to take account of the number
of features $p$:</p>

\[R^2_{adj} = 1 - \frac{RSS/(n-p)}{TSS/(n-1)}\]

<ul>
  <li><strong>Confidence intervals</strong></li>
</ul>

<p>Confidence interval with the confidence $C$ means that the estimator will have
the value within the interval with the probability $C$.
I won‚Äôt go through the technical details of the derivation for those formulas,
but it‚Äôs worth to mention the full forms. As it is known that</p>

\[\frac{\hat\beta_k - \beta_k}{se(\hat\beta_k)} \sim t_{1-\alpha/2,\ n-p},\]

<p>we can say $(1-\alpha) \cdot 100$% confidence interval for $\beta_k$ is</p>

\[CI(\beta_k, (1-\alpha) \cdot 100) = \hat\beta_k \pm se(\hat\beta_k) \cdot t_{1-\alpha/2, n-p}.\]

<p>The range terms consist of the <em>point estimate</em>, the <em>estimated standard error
of the point estimate</em>, and the <em>quantile of the relevant distribution</em>. This
format holds for the other confidence intervals. For example, consider the new
data $\mathbf{x}_0$. The confidence intervals for $\mathbb{E} y_0$ and $y_0$ are:</p>

\[CI(\mathbb{E} y_0, (1-\alpha) \cdot 100) = \mathbf{x}_0^\intercal \hat\beta \pm \hat\sigma \sqrt{\mathbf{x}_0^\intercal (\mathbf{X}^\intercal \mathbf{X})^{-1} \mathbf{x}_0} \cdot t_{1-\alpha/2,\ n-p},\]

\[CI(y_0, (1-\alpha) \cdot 100) = \mathbf{x}_0^\intercal \hat\beta \pm \hat\sigma \sqrt{1+\mathbf{x}_0^\intercal (\mathbf{X}^\intercal \mathbf{X})^{-1} \mathbf{x}_0} \cdot t_{1-\alpha/2,\ n-p}.\]

<h3 id="pros-and-cons-on-interpretability">Pros and cons on interpretability</h3>

<p>So far we took a look for the linear regression and how we interpret the results
from the algorithm. Here, we summarise the merits and drawbacks of the linear
regression in the eyes of interpretability. Based on the criteria on <a href="https://christophm.github.io/interpretable-ml-book/explanation.html#good-explanation">the Human-Friendly Explanations</a>,</p>

<ul>
  <li><strong>Explanations are contrastive:</strong> YES, but has limitation on the highly unrealistic
setting of standardised data points.</li>
  <li><strong>Explanations are selected:</strong> NO, because the model does not select from the
other options. Linear regression just calculate the weights by the formulas.</li>
  <li><strong>Explanations are truthful:</strong> YES. As long as the data is nicely prepared, 
no other term can interfere the calculation during the inference time.</li>
  <li><strong>Explanations are general and probable:</strong> YES. So clear mathematical foundations.</li>
</ul>

<p>Other criteria relate on the social aspects, so we can say it depends on the
interpreter of the resulting model.</p>

<p>Hence, long story short, linear regression generally works well, but only on the
specific settings and assumptions. Keep in mind that this is the simplest form,
and statistics community has already developed Generalised Linear Models (GLM) or
Generalised Additive Models (GAM) to mitigate the weakness of the vanilla linear regression.
I do not have a plan to go deeper for those topics, so pleas refer Molnar‚Äôs
explanation on it <a href="https://christophm.github.io/interpretable-ml-book/extend-lm.html">here</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Molnar, Christoph, Interprebatle Machine Learning - A Guide for Making Black Models Explainable (2021), <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a>¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a>¬†<a href="#fnref:1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>
:ET